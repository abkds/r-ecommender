{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import csv \n",
    "import scipy\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from implicit import alternating_least_squares\n",
    "from implicit import approximate_als\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('interactions_30_ch_no_bots') as csvfile:\n",
    "    datareader = csv.reader(csvfile, delimiter = ' ')\n",
    "    for subreddit, user, comments, _ in datareader:\n",
    "        data.append([user, subreddit, int(comments)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['user', 'subreddit', 'comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user'] = data['user'].astype(\"category\")\n",
    "data['subreddit'] = data['subreddit'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sparse matrix of all the artist/user/play triples\n",
    "comments = coo_matrix((data['comments'].astype(float), \n",
    "                   (data['subreddit'].cat.codes, \n",
    "                    data['user'].cat.codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis ( Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toggle this variable if you want to recalculate the als factors\n",
    "read_als_factors_from_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_als_factors_from_file:\n",
    "    subreddit_factors = np.load('subreddit_factors_als.npy')\n",
    "    user_factors = np.load('user_factors_als.npy')\n",
    "else:\n",
    "    subreddit_factors, user_factors = alternating_least_squares(bm25_weight(comments), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n",
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 15.0/15 [02:26<00:00,  9.15s/it]\n"
     ]
    }
   ],
   "source": [
    "subreddit_factors, user_factors = alternating_least_squares(bm25_weight(comments), 20, use_gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopRelated(object):\n",
    "    def __init__(self, subreddit_factors):\n",
    "        norms = np.linalg.norm(subreddit_factors, axis=-1)\n",
    "        self.factors = subreddit_factors / norms[:, np.newaxis]\n",
    "        self.subreddits = data['subreddit'].cat.categories.array.to_numpy()\n",
    "\n",
    "    def get_related(self, subreddit, N=10):\n",
    "        subreddit_hits = np.where(self.subreddits == subreddit)\n",
    "        print(subreddit_hits)\n",
    "        if not any(subreddit_hits[0]):\n",
    "            print(\"In our world your SubReddit does not exist!!!\")\n",
    "            return \n",
    "        subredditid = subreddit_hits[0][0]\n",
    "        scores = self.factors.dot(self.factors[subredditid])\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        best_ = [self.subreddits[i] for i in best]\n",
    "        return sorted(zip(best_, scores[best]), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_related = TopRelated(subreddit_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([23623], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bleach', 1.0),\n",
       " ('OnePiece', 0.9817828),\n",
       " ('Naruto', 0.9807206),\n",
       " ('UNAMmx', 0.96712846),\n",
       " ('Seinen', 0.9622733),\n",
       " ('OnePunchMan', 0.9606999),\n",
       " ('CodeGeass', 0.96038693),\n",
       " ('manga', 0.9593556),\n",
       " ('HunterXHunter', 0.9584304),\n",
       " ('FullmetalAlchemist', 0.95777917)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_related.get_related('bleach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41143, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-19f5e860be90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubreddits_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubreddit_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msubreddits_embedded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "subreddits_embedded = umap.UMAP().fit_transform(subreddit_factors)\n",
    "subreddits_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = data['subreddit'].cat.categories.array.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "indices = random.sample(range(len(subreddits)), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_subreddits = subreddits[indices]\n",
    "sampled_subreddits_embedded = subreddits_embedded[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_credentials_file(username='abkds', api_key='KKuXHMUKu7EHg9kIZWrl')\n",
    "\n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "N = 500\n",
    "xs = sampled_subreddits_embedded[:, 0]\n",
    "ys = sampled_subreddits_embedded[:, 1]\n",
    "\n",
    "# Create a trace\n",
    "trace = go.Scatter(\n",
    "    x = xs,\n",
    "    y = ys,\n",
    "    mode='markers+text',\n",
    "    text=sampled_subreddits\n",
    ")\n",
    "\n",
    "data_ = [trace]\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "py.iplot(data_, filename='basic-scatter')\n",
    "\n",
    "# or plot with: plot_url = py.plot(data, filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "\n",
    "params = {\"factors\": 63}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27148, 1113188), 86.0\n",
      "(27148, 824475), 30.0\n",
      "(27148, 747152), 9.0\n",
      "(27148, 726613), 1.0\n",
      "(27148, 2314515), 84.0\n",
      "(27148, 1640350), 52.0\n",
      "(27148, 1206063), 17.0\n",
      "(27148, 1491311), 71.0\n",
      "(27148, 1003607), 165.0\n",
      "(27148, 2089596), 15.0\n"
     ]
    }
   ],
   "source": [
    "cx = comments\n",
    "\n",
    "k = 0\n",
    "for i, j, v in zip(comments.row, cx.col, cx.data):\n",
    "    if k == 10:\n",
    "        break\n",
    "    print( \"(%d, %d), %s\" % (i,j,v) )\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tqdm\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianPersonalizedRanking(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bpr'\n",
    "output_filename = 'subreddits_recs_bpr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100/100 [00:43<00:00,  2.34it/s, correct=95.78%, skipped=7.16%]\n"
     ]
    }
   ],
   "source": [
    "model.fit(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_related_subreddits(subreddit):\n",
    "    found = np.where(subreddits == subreddit)\n",
    "    if len(found[0]) == 0:\n",
    "        raise ValueError(\"Subreddit doesn't exist in the dataset.\")\n",
    "    _id = found[0][0]\n",
    "    return [(subreddits[i], v) for i, v in model.similar_items(_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OnePiece', 3.054841),\n",
       " ('BokuNoHeroAcademia', 2.8956935),\n",
       " ('HunterXHunter', 2.8327653),\n",
       " ('Naruto', 2.809574),\n",
       " ('fairytail', 2.8008738),\n",
       " ('Toriko', 2.7774673),\n",
       " ('bleach', 2.7609572),\n",
       " ('Gintama', 2.6900525),\n",
       " ('OnePieceCircleJerk', 2.6743338),\n",
       " ('NanatsunoTaizai', 2.6683886)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_related_subreddits('OnePiece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data['user'].cat.categories.array.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate recommendations for each user and write out to a file\n",
    "user_comments = comments.T.tocsr()\n",
    "\n",
    "with tqdm.tqdm_notebook(total=len(users)) as progress:\n",
    "    with codecs.open(output_filename, \"w\", \"utf8\") as o:\n",
    "        for userid, username in enumerate(users):\n",
    "            for subredditid, score in model.recommend(userid, user_comments):\n",
    "                o.write(\"%s\\t%s\\t%s\\n\" % (username, subreddits[subredditid], score))\n",
    "            progress.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample user recommendations\n",
    "\n",
    "We went through the user 'xkcd_transciber' list of subreddits, where he/she commented. Taking a view of the kind of subreddits followed by the user we see that the predictions are good. This is just one sample, we are saving the recommendations for all users in a file and will also write the AUC score function for getting the exact scores for the generated recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user(username):\n",
    "    sample_user_id = np.where(users == username)[0][0]\n",
    "    return [(subreddits[i], v) for i, v in model.recommend(2293528, user_comments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_for_user('xkcd_transcriber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subreddits_interacted_by_user(username):\n",
    "    sample_user_id = np.where(users == username)[0][0]\n",
    "    _idlist =  comments.getcol(sample_user_id)\n",
    "    return [subreddits[idx] for idx, i in enumerate(xkcd.toarray()) if i != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 50 reddits with which xkcd_transcriber has interacted with.\n",
    "random.sample(subreddits_interacted_by_user('xkcd_transcriber'), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 41143/41143 [00:04<00:00, 9102.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import implicit.nearest_neighbours \n",
    "import numpy as np\n",
    "\n",
    "bm25recommender = implicit.nearest_neighbours.BM25Recommender()\n",
    "bm25recommender.fit(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simililar(subreddit, model):\n",
    "    found = np.where(subreddits == subreddit)\n",
    "    if len(found[0]) == 0:\n",
    "        raise ValueError(\"Subreddit doesn't exist in the dataset.\")\n",
    "    _id = found[0][0]\n",
    "    return [(subreddits[i], v) for i, v in model.similar_items(_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relationship_advice', 56264.860356837584),\n",
       " ('relationships', 7646.369998617379),\n",
       " ('sex', 3620.3338698129846),\n",
       " ('dating_advice', 3464.2280969267954),\n",
       " ('Advice', 2987.466870557861),\n",
       " ('DeadBedrooms', 2613.245492302089),\n",
       " ('Marriage', 2289.7037608953324),\n",
       " ('confession', 2212.4492161185867),\n",
       " ('offmychest', 1906.8668341457656),\n",
       " ('askwomenadvice', 1890.3259544583016)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simililar('relationship_advice', bm25recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 41143/41143 [00:01<00:00, 25334.11it/s]\n"
     ]
    }
   ],
   "source": [
    "cosine_recommender = implicit.nearest_neighbours.CosineRecommender()\n",
    "cosine_recommender.fit(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relationship_advice', 1.0000000000001017),\n",
       " ('junkojunsui', 0.2294500237344137),\n",
       " ('Controversy', 0.10987747615450796),\n",
       " ('relationships', 0.10444737538547606),\n",
       " ('badparents', 0.0687772524582305),\n",
       " ('Advice', 0.06377708722197854),\n",
       " ('OneY', 0.06206601341100445),\n",
       " ('dating_advice', 0.05847217068137823),\n",
       " ('Marriage', 0.054288376156235725),\n",
       " ('postnationalist', 0.05180502196499363)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simililar('relationship_advice', cosine_recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 41143/41143 [00:01<00:00, 25148.53it/s]\n"
     ]
    }
   ],
   "source": [
    "item_item_recommender = implicit.nearest_neighbours.ItemItemRecommender()\n",
    "item_item_recommender.fit(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relationship_advice', 1532006.0),\n",
       " ('relationships', 624468.0),\n",
       " ('AskReddit', 426470.0),\n",
       " ('sex', 93304.0),\n",
       " ('AskWomen', 74514.0),\n",
       " ('Advice', 70018.0),\n",
       " ('AskMen', 57261.0),\n",
       " ('TwoXChromosomes', 52129.0),\n",
       " ('funny', 49147.0),\n",
       " ('todayilearned', 47359.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simililar('relationship_advice', item_item_recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 41143/41143 [00:01<00:00, 27210.93it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_recommender = implicit.nearest_neighbours.TFIDFRecommender()\n",
    "tf_idf_recommender.fit(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relationship_advice', 1.0000000000000269),\n",
       " ('relationships', 0.1485194909573468),\n",
       " ('junkojunsui', 0.09118742669753052),\n",
       " ('sex', 0.07145533336297871),\n",
       " ('Controversy', 0.0683580169544256),\n",
       " ('dating_advice', 0.06248236304658284),\n",
       " ('Advice', 0.05464629578540297),\n",
       " ('Marriage', 0.04939810870950803),\n",
       " ('AskWomen', 0.045036999780776604),\n",
       " ('datingoverthirty', 0.04339423672382081)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simililar('relationship_advice', tf_idf_recommender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURPRISE MADAFAQAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdpp = surprise.SVDpp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = surprise.Reader()\n",
    "dataset = surprise.Dataset.load_from_df(data, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the trainset\n",
    "trainset = dataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdpp.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = svdpp.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exmormon'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'][0000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-6a1f0fdfebb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubreddits\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'vv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubreddits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "found = np.where(subreddits == 'vv')\n",
    "_id = found[0][0]\n",
    "subreddits[np.argsort(a[_id])[::-1][0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'arg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-1d2eb5591ddd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'arg'"
     ]
    }
   ],
   "source": [
    "help(np.arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
